# Review

![Human Compatible by Stuart Russell][1]

> ©2020 Stuart Russell. All rights reserved.

Before any words about the book, i would like to make a disclaimer here: I didn't read the book!

Instead i bought the Audible version and listen in my day to day going to work. It's a good alternative for one that don't have good quality time to seat down and read (if you are a parent with a newborn child, you get the ideia).

Anyway, let's get to the book...

---

## Success, Progress and Misuses of AI

In the first chapter of the book, prof. Russell exposes some explanation about what may happen if we succeed in build **Human Level AI**, what the progress AI could bring in the future (presenting here explanations about self-Driving cars, personal assistants, domestic robots and other) and some misuses of AI, like Surveillance. He also talks about one of the most important and most of the time unclear definition of the word intelligence.

"_Before we can understand how to create intelligence, it helps to understand what it is. The answer is not to be found in IQ tests, or even in Turing tests, but in a simple relationship between what we perceive, what we want, and what we do. Roughly speaking, an entity is intelligent to the extent that what it does is likely to achieve what it wants, given what it has perceived._"

And that "definition" propose by prof. Russell will keep appear in all other parts of the book.

In my understand this definition is excellent, because (as prof. Russell exposes in his book), demonstrate that intelligence is beyond human intelligence, and other agents in our world could demonstrate some kind of intelligent behavior. This view could allow one to improve its knowledge of the world and the view of what even intelligent beings are we.

Also, as already said by, for example, Yann LeCun, Human Level Intelligence is not that general, it main seem general, but it lacks true generality, for example, we as human (or most of us) could not work (or visualize data) in higher dimensions, a trivial matter for machines.

"_There is no such thing as Artificial General Intelligence because there is no such thing as General Intelligence. Human intelligence is very specialized._" [Yann LeCun][2]

Also in this topic, there's an excellent paper written by François Chollet, called ["_On the Measure of Intelligence_"][3].

## Gorilla and King Midas problem

In chapter 5, prof. Russell exposes and explore two types of problems that human race could face in case AI become **overly intelligent** (the name of the chapter).

The Gorilla problem resolves as the possibility of us human to still maintain control of overly intelligent machines. As prof. Russell exposes:

"_...specifically, the problem of whether humans can maintain their supremacy and autonomy in a world that includes machines with substantially greater intelligence._"

The other problem explained in the book, the King Midas, resolves itself as it is impossible to model in machines the human true desire.

"_...the impossibility of defining true human purposes correctly and completely. This, in turn, means that what I have called the standard model—whereby humans attempt to imbue machines with their own purposes—is destined to fail._"

This second problem is clearly visible nowdays in applications of RL (**Reinforcement Learning**), where we need to provide the agents with good/bad feedback about the actions they make in the environment their are working on. It's hard to provide good/bad feedback in restricted environments (like simulations), imagine, provide feedback in the open world of our lives.

## Chapters 6 to 10

The next chapters is an exploration of the previous two problems presented early. In anyway those chapters are shallow, it brings up lot's of questions and possible answers.

Starting in chapter 6, prof. Russell presents us with a few thought stereotypes about the debate of the new intelligent species (the overly intelligent machines).

The two next chapters are very interesting, the exploration of how to build beneficial machines, "explain" to them our preferences and ensure that these preferences are truly applied, having guarantees that the machines are working correctly.

The last chapter (not counting here the chapter 10 which is kind of a conclusion), prof. Russell brings to the table the problem of having humans interacting with machines. Specially lot's of different humans, with different preferences.

"_...we don’t want it to have one correct value system of its own; we just want it to predict the preferences of others._"

"_The presence of more than one person in the world has another important consequence: it means that, for each person, there are other people to care about. This means that satisfying the preferences of an individual has implications for other people, depending on the individual’s preferences about the well-being of others._"

## Appendix

The appendixes brings more depth to the talk, but they are a little bit more technical. In one of then, prof. Russell explain **Propositional logic** and **First-order logic**, in the next he talks about **Probability Theory**, given as an example **Bayesian Networks** (created by Judea Pearl in the 80s) and **Probabilistic Programming Languages (PPL)**.

In the last appendix he addressed the topic of learning from experience, where the most notable advance today comes from Deep Learning.

## Conclusion

The book itself is very well written and brings to the table of discussion good topics. Since it's not a pure technical reading you could finish the book in a brief (a week or maybe two, or even less time).

To **buy** the book or the **Audible** version:

[Human Compatible: Artificial Intelligence and the Problem of Control][4]

Thanks

[1]: /static/pages/essays/6/human_compatible.jpeg
[2]: https://twitter.com/ylecun/status/1204013978210320384
[3]: https://arxiv.org/abs/1911.01547
[4]: https://www.amazon.com/Human-Compatible-Artificial-Intelligence-Problem/dp/0525558616/ref=sr_1_1?keywords=human%20compatible&qid=1581349563&sr=8-1
